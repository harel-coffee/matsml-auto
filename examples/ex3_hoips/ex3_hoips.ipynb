{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training ML models for computed band gap of HOIPs\n",
    "### Huan Tran, MSE, Georgia Institute of Technology\n",
    "\n",
    "This notebook is a part of [V. N. Tuoc, Nga. T. T. Nguyen, V. Sharma, and T. D. Huan, *Probabilistic deep learning approach for targeted hybrid organic-inorganic perovskites*, 2021]. \n",
    "\n",
    "The original dataset containing the computed band gap of 1,346 atomic structures predicted for 192 chemical compositions of hybrid organic-inorganic perovskites (HOIPs) is available at [C. Kim, T.D. Huan, S. Krishnan, and R. Ramprasad, Scientific Data 4, 170057 ('17), url: https://www.nature.com/articles/sdata201757]. Herein, three fingerprinted versions of this dataset will be fetched and learned to develop 5 ML models, which are based on Gaussian Process Regression, fully connected Neural Net, and Probability Neural Net. The last one supplies a good way to handle aleatoric (data) uncertainty. Details on this topic can be found in the original reference mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  matsML, a ML toolkit for some problems in materials science\n",
      "  Huan Tran, huantd@gmail.com\n",
      "  *****\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matsml.models import ProbNeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data parameters\n",
    "data_file = 'hoips_4tfp.csv'\n",
    "id_col = ['ID']\n",
    "y_cols = ['Egap']\n",
    "comment_cols = []\n",
    "n_trains = 0.85\n",
    "sampling = 'random'\n",
    "x_scaling = 'minmax'\n",
    "y_scaling = 'minmax'\n",
    "data_params = {'data_file':data_file, 'id_col':id_col,'y_cols':y_cols,\n",
    "    'comment_cols':comment_cols,'y_scaling':y_scaling,'x_scaling':x_scaling,\n",
    "    'sampling':sampling, 'n_trains':n_trains}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "layers = [5,5]                   # list of nodes in hidden layers\n",
    "epochs = 100                     # Epochs\n",
    "nfold_cv = 5                     # Number of folds for cross validation\n",
    "use_bias = True                  # Use bias term or not\n",
    "file_model = 'model.pkl'         # Name of the model file to be created\n",
    "loss = 'mse'                     #\n",
    "metric = 'mse'                   #\n",
    "verbosity = 0\n",
    "batch_size = 32                  #\n",
    "activ_funct = 'elu'              # Options: \"tanh\",\"relu\",\"sigmoid\",\"softmax\", \n",
    "                                 # \"softplus\",\"softsign\",\"selu\",\"elu\",\n",
    "                                 # \"exponential\"\n",
    "optimizer = 'nadam'              # options: \"SGD\",\"RMSprop\",\"Adam\",\"Adadelta\", \n",
    "                                 # \"Adagrad\",\"Adamax\",\"Nadam\",\"Ftrl\"\n",
    "\n",
    "model_params={'layers':layers,'activ_funct':activ_funct,'epochs':epochs,\n",
    "    'nfold_cv':nfold_cv,'optimizer':optimizer,'use_bias':use_bias,\n",
    "    'file_model':file_model,'loss':loss,'metric':metric,\n",
    "    'batch_size':batch_size,'verbosity':verbosity,'rmse_cv':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "  Learning fingerprinted/featured data\n",
      "    algorithm                    Probabilistic NeuralNet w/ TensorFlow-Probability\n",
      "    layers                       [5, 5]\n",
      "    activ_funct                  elu\n",
      "    epochs                       100\n",
      "    optimizer                    nadam\n",
      "    nfold_cv                     5\n"
     ]
    }
   ],
   "source": [
    "# Compile a model\n",
    "model=ProbNeuralNet(data_params=data_params,model_params=model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Reading data ... \n",
      "    data file                    hoips_4tfp.csv\n",
      "    data size                    1346\n",
      "    training size                1144 (85.0 %)\n",
      "    test size                    202 (15.0 %)\n",
      "    x dimensionality             221\n",
      "    y dimensionality             1\n",
      "    y label(s)                   ['Egap']\n",
      "  Preprocessing data ...\n",
      "    scaling x                    minmax\n",
      "    scaling y                    minmax\n",
      "    prepare train/test sets      random\n",
      "  Building model: ProbNeuralNet\n",
      "  Training ProbNeuralNet w/ cross validation\n",
      "    cv,rmse_train,rmse_test,rmse_opt: 0 0.130835 0.129978 0.129978\n",
      "    cv,rmse_train,rmse_test,rmse_opt: 1 0.133496 0.132256 0.129978\n",
      "    cv,rmse_train,rmse_test,rmse_opt: 2 0.129701 0.121604 0.121604\n",
      "    cv,rmse_train,rmse_test,rmse_opt: 3 0.138079 0.119489 0.119489\n",
      "    cv,rmse_train,rmse_test,rmse_opt: 4 0.134343 0.132062 0.119489\n",
      "    Optimal ncv:  3\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
